---
title: "Ethics of Algorithms"
---

Team 3:  Cody Lundell, Christina Worden, Dan Gabiou

# Topic Overview of Chapter 13: Ethics of Algorithms
Chapter 13’s readings include Chapter 9 and the Conclusion chapter for O’Neil’s Weapons of Math Destruction book. O’Neil (2016) begins Chapter 9 with a history lesson reminding us of examples of the social injustices (correlation without causation) resulting from poor interpretation of data; with the first example being early insurance companies refusing to insure African American people (p. 162). Although we have evolved as a society, are insurance companies still a Weapon of Math Destruction (WMD)?

As more data is becoming available to track our every move and error, insurance companies can begin to target and customize insurance rates. But is this a good thing? O’Neil provides examples of modern day companies using demographics to target groups less likely to shop for lower insurance rates and jack up rates. In other companies, credit scores are used as an easily-accessible data source, yet such statistic may have no direct correlation to driver behavior. In New York for example, drivers with just a “good” credit score may pay $255 more per year than those with an “excellent” credit score and in Florida, drivers with clean records, but poor credit scores paid $1,552 per year than those with a DUI and an excellent credit score (O’Neil, 2016, p. 165). The overarching trend is that insurance companies will no longer adjust rates based on age, gender, net worth, or zip code; access to more big data allows insurance companies to adjust rates based on “behavioral tribes” generated by electronic data, like phone data (O’Neil, 2016, p. 171). But wait, there’s more. New, nontraditional methods of collecting data, like employee health programs are no targeting “unhealthy” employees who are not meeting their employee health program weight loss goals by forcing such people to pay out of pocket expenses. To make matters worse, some companies, like CVS, actually require employees to report their body fat, blood sugar, blood pressure, and cholesterol, or pay a $600 fine annually (O’Neil, 2016, p. 176).

So what conclusions can we draw from our Weapons of Math Destruction book? WMDs are caused by poor interpretations of available data, often the most easily-accessible data. Our poorest populations are particularly being targeted by companies who overgeneralize personal data, demographics, geographic areas, and other data. We have a challenge ahead as a society which will only intensify as technology and data become more available. Could regulations help? Will ethics prevail over corporate greed? Or will WMDs, accompanied by causation without correlation result in history repeating itself? Hopefully, knowledge and awareness will counter WMDs from spreading and causing further harm to society.

## Chapter Summaries

## *Weapons of Math Destruction*, Chapter 9 Summary 

Covered in Chapter 9 is the process of being insured. O’Neil (2016) explores the algorithms behind auto and health insurance.
Her findings show that there are implicit bias within the calculations that determine how a driver or individual is insured
both in auto and health insurance, respectively. These biases often disadvantage minority and poor populations. For example, 
driver with an excellent driving record who has a low credit score would likely have a more expensive auto insurance rate.
Comparatively, it was found that a driver with a DUI on their record who has a high credit score would have a cheaper auto
insurance rate. 

O’Neil (2016) also covers employer wellness programs that are often created as a part of employee health insurance. Many
employer wellness programs, in an effort to lower rates and encourage employee healthy behaviors, have employees share health
data. This data can then be used to show to health insurance companies that employers are making the effort to try to
encourage employees to lose weight, etc. O’Neil cautions that if employers take the next step and create their own health and
productivity models the result could be a serious WMD.

## *Weapons of Math Destruction*, Conclusion Summary

About a year ago, I found myself leaving my house to pick up some ice-cream on a typical Friday night for my wife and myself.
With three young children, home dates have been the norm for many years. Recently, we found a new ice-cream place. We must
have gone there regularly for a few months at a similar time and at a similar date because my phone knew exactly where I was
going. As soon as I started my car, my phone told me that it was 10 minutes from the ice-cream parlor referencing the store by
name and offered step-by-step directions. I did not ask for it or set it up, but it remembered. There was an algorithm built
and deployed based on my personal habits. I never gave consent nor did I realize that there was a trend. Trends and habits are
what typically are used for big data analysis. In terms of *Weapons of Math Destruction*, the entire book identifies specific
stages or scenarios in life where data is analyzed based on individual or collective behavior. A recurring theme is the
discussion of over regulated and unregulated data gathering and computation. Data mining and algorithmic societies find ways
to better life and influence behavior for the better. I guess the concern for a WMD is when it is taken too far. 

### Key Take-aways:

* Does the content of this class make you think about your own vulnerabilities as a data point on a spreadsheet?
* How to determine when data analysis becomes invasive and controlling?
* Are we living a life guided by data gutter guards?
* Who is in control of our data destiny?


## References

1.	O'Neil, C. (2016). Weapons of math destruction: How big data increases inequality and threatens democracy. Broadway Books. **CH9 getting insurance**
2.	O'Neil, C. (2016). Weapons of math destruction: How big data increases inequality and threatens democracy. Broadway Books. **conclusion**

